{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCAP Analysis\n",
    "\n",
    "Sources : \n",
    "- https://adriangcoder.medium.com/pandas-tricks-and-tips-a7b87c3748ea\n",
    "- https://www.stamus-networks.com/blog/jupyter-playbooks-for-suricata-part-3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Certains outils ont été spécialement développés pour analyser le traffic réseau et détecter à travers des règles définies, un comportement malveillant/suspect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import ipaddress as ip\n",
    "from msticpy.transform.iocextract import IoCExtract\n",
    "# Instantiate an IoCExtract object\n",
    "#from msticpy.transform import IoCExtract\n",
    "ioc_extractor = IoCExtract()\n",
    "\n",
    "import msticpy as mp\n",
    "mp.init_notebook(globals(), verbosity=0)\n",
    "ti = mp.TILookup()\n",
    "ioc_extract = IoCExtract()\n",
    "\n",
    "#Expand the width of the cells\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def ip_type(string):\n",
    "    if ip.ip_address(string).is_private:\n",
    "        return 'Private'\n",
    "    elif ip.ip_address(string).is_multicast:\n",
    "        return 'Multicast'\n",
    "    elif ip.ip_address(string).is_reserved:\n",
    "        return 'Reserved'\n",
    "    elif ip.ip_address(string).is_loopback:\n",
    "        return 'Loopback'\n",
    "    elif ip.ip_address(string).is_global:\n",
    "        return 'Public'\n",
    "    elif ip.ip_address(string).is_link_local:\n",
    "        return 'Link local'\n",
    "\n",
    "\n",
    "\n",
    "# Set pcap file path\n",
    "pcapFile = {}\n",
    "pcapFile_path = \"XXXXXXxxxxx.pcap\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse rapide du PCAP via Tshark\n",
    "\n",
    "Il est possible de parcourir facilement le contenu d'un fichier PCAP grâce à l'outil : **tshark**, une version console de l'outil **wireshark**.\n",
    "\n",
    "```\n",
    "# Read all pcap file \n",
    "$ tshark -r {pcap_filepath}\n",
    "\n",
    "# Read all pcap file without resolve domain name \n",
    "$ tshark -nr {pcap_filepath}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des conversations **TCP** présentes au sein du PCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tshark -nr $pcapFile_path -q -z conv,tcp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des conversations **UDP** présentes au sein du PCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tshark -nr $pcapFile_path -q -z conv,udp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'aller plus loin via l'usage de filtres.\n",
    "\n",
    "* Filter on HTTP method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tshark -r $pcapFile_path -Y \"http.request.method==GET\" | grep -i 'swellheaded.php'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all HTTP requests and URLs : \\\n",
    "It could be interesting to identify exe or archive downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tshark -r $pcapFile_path -Y 'ip.src == 1.2.3.4 and http.request.method == \"GET\"' -T fields -e http.request.method -e http.request.version -e http.request.full_uri | head -n 1\n",
    "!tshark -nr $pcapFile_path -Y 'http.request.method == \"POST\" or http.request.method == \"GET\"' -T fields -e tcp.stream  -e http.request.method -e http.request.version -e http.request.full_uri | egrep -i '.zip|.exe'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all data about a specific tcp stream id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tshark -nr $pcapFile_path -Y 'tcp.stream == 119' -T fields -e data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tshark -nr $pcapFile_path -Y 'http.request.method == \"POST\" or http.request.method == \"GET\"' -T fields -e tcp.stream  -e http.request.method -e http.request.version -e http.request.full_uri -e data.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show all User-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tshark -nr $pcapFile_path -Y \"http.user_agent\" -Tfields -e ip.addr -e http.user_agent "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "source : https://jsur.in/post/2020-02-19-tshark-cheatsheet\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse du PCAP via Suricata\n",
    "\n",
    "Une fois l'analyse rapide terminée, il est important de faire appel à des moteurs de détection type NIDS, spécialisé Réseau, tel que **Suricata**. \n",
    "Avant de débuter l'analyse du pcap, il est indispensable de mettre à jour les règles de détection ```suricata-update```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"/tmp/suricata/logs\"\n",
    "!rm -rf $LOGDIR 2>/dev/null; mkdir -p $LOGDIR\n",
    "\n",
    "# Update rules\n",
    "!sudo suricata-update 1>/dev/null\n",
    "\n",
    "# Start analyse\n",
    "!suricata -S /var/lib/suricata/rules/suricata.rules -r $pcapFile_path -l $LOGDIR -v "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si Suricata identifie à travers ses règles des indicateurs de compromissions, alors le nombre d'alerte devrait être supérieur à 0. \n",
    "\n",
    "Si tel est le cas, ces alertes sont consultables au sein du fichier eve.json ou fast.log. \\\n",
    "Les étapes suivantes considèrent que des alertes ont été générées. L'action initiale consiste donc à parcourir le fichier **eve.json** et le charger dans un dataFrame pour analyser plus facilement les données qu'il contient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nested eve.json in dataFrame\n",
    "with open(f\"{ LOGDIR }/eve.json\", \"r\") as eveFile:\n",
    "    df_suricata = pd.json_normalize([\n",
    "        json.loads(line) for line in eveFile\n",
    "    ], max_level=1)\n",
    "\n",
    "df_suricata['flow_id'] = df_suricata['flow_id'].fillna(0).astype(int)\n",
    "df_suricata['alert.signature_id'] = df_suricata['alert.signature_id'].fillna(0).astype(int)\n",
    "df_suricata['dest_port'] = df_suricata['dest_port'].fillna(0).astype(int)\n",
    "df_suricata['src_port'] = df_suricata['src_port'].fillna(0).astype(int)\n",
    "\n",
    "df_suricata['flow.start'] = pd.to_datetime(df_suricata['flow.start'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_suricata['timestamp'] = pd.to_datetime(df_suricata['timestamp'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://github.com/Cyb3r-Monk/RITA-J/blob/main/C2%20Detection%20-%20HTTP.ipynb\n",
    "\n",
    "columns_to_display = ['Score','tsScore','dsScore','connections_count','src_ip','dest_ip','dest_port','proto']\n",
    "columns_to_filter = ['timestamp','src_ip','dest_ip','dest_port','proto','flow.bytes_toserver']\n",
    "columns_to_groupby = ['src_ip','dest_ip','dest_port','proto']\n",
    "df_beacon = df_suricata[columns_to_filter]\n",
    "df_beacon = df_beacon.drop_duplicates(subset=columns_to_filter)\n",
    "\n",
    "df_beacon = df_beacon[df_beacon['flow.bytes_toserver'].notnull()]\n",
    "df_beacon = df_beacon.groupby(columns_to_groupby).agg(list)\n",
    "df_beacon.reset_index(inplace=True)\n",
    "\n",
    "# Calule le nombre de connexions répondant aux mêmes critères ip_source, ip_destination, port_destination, protocole\n",
    "df_beacon['connections_count'] = df_beacon['timestamp'].apply(lambda x: len(x))\n",
    "\n",
    "# Application d'un seuil de connexion minimal à obtenir par critère\n",
    "df_beacon = df_beacon.loc[df_beacon['connections_count'] > 20]\n",
    "\n",
    "# Tri des connexions par connections_count\n",
    "df_beacon = df_beacon.sort_values(['connections_count'], ascending=False)\n",
    "\n",
    "# Tri des connexions par timestamp\n",
    "df_beacon['timestamp'] = df_beacon['timestamp'].apply(lambda x: sorted(x))\n",
    "\n",
    "# Calcul du delta entre les paquets / Suppression des deltas = 0 qui n'apporterait pas de plus-value\n",
    "df_beacon['deltas'] = df_beacon['timestamp'].apply(lambda x: pd.Series(x).diff().dt.seconds.dropna().tolist())\n",
    "\n",
    "# Variables for time delta dispersion\n",
    "df_beacon['tsLow'] = df_beacon['deltas'].apply(lambda x: np.percentile(np.array(x), 20))\n",
    "df_beacon['tsMid'] = df_beacon['deltas'].apply(lambda x: np.percentile(np.array(x), 50))\n",
    "df_beacon['tsHigh'] = df_beacon['deltas'].apply(lambda x: np.percentile(np.array(x), 80))\n",
    "df_beacon['tsBowleyNum'] = df_beacon['tsLow'] + df_beacon['tsHigh'] - 2*df_beacon['tsMid']\n",
    "df_beacon['tsBowleyDen'] = df_beacon['tsHigh'] - df_beacon['tsLow']\n",
    "df_beacon['tsSkew'] = df_beacon[['tsLow','tsMid','tsHigh','tsBowleyNum','tsBowleyDen']].apply(\n",
    "    lambda x: x['tsBowleyNum'] / x['tsBowleyDen'] if x['tsBowleyDen'] != 0 and x['tsMid'] != x['tsLow'] and x['tsMid'] != x['tsHigh'] else 0.0, axis=1\n",
    "    )\n",
    "df_beacon['tsMadm'] = df_beacon['deltas'].apply(lambda x: np.median(np.absolute(np.array(x) - np.median(np.array(x)))))\n",
    "df_beacon['tsConnDiv'] = df_beacon['timestamp'].apply(lambda x: (x[-1].to_pydatetime() - x[0].to_pydatetime()).seconds / 90)\n",
    "\n",
    "# Variables for data size dispersion\n",
    "df_beacon['dsLow'] = df_beacon['flow.bytes_toserver'].apply(lambda x: np.percentile(np.array(x), 20))\n",
    "df_beacon['dsMid'] = df_beacon['flow.bytes_toserver'].apply(lambda x: np.percentile(np.array(x), 50))\n",
    "df_beacon['dsHigh'] = df_beacon['flow.bytes_toserver'].apply(lambda x: np.percentile(np.array(x), 80))\n",
    "df_beacon['dsBowleyNum'] = df_beacon['dsLow'] + df_beacon['dsHigh'] - 2*df_beacon['dsMid']\n",
    "df_beacon['dsBowleyDen'] = df_beacon['dsHigh'] - df_beacon['dsLow']\n",
    "df_beacon['dsSkew'] = df_beacon[['dsLow','dsMid','dsHigh','dsBowleyNum','dsBowleyDen']].apply(\n",
    "    lambda x: x['dsBowleyNum'] / x['dsBowleyDen'] if x['dsBowleyDen'] != 0 and x['dsMid'] != x['dsLow'] and x['dsMid'] != x['dsHigh'] else 0.0, axis=1\n",
    "    )\n",
    "df_beacon['dsMadm'] = df_beacon['flow.bytes_toserver'].apply(lambda x: np.median(np.absolute(np.array(x) - np.median(np.array(x)))))\n",
    "\n",
    "# Time delta score calculation\n",
    "df_beacon['tsSkewScore'] = 1.0 - abs(df_beacon['tsSkew'])\n",
    "# If jitter is greater than 30 seconds, say 90 seconds, MadmScore might be zero\n",
    "# It depends on how the jitter is implemented.\n",
    "df_beacon['tsMadmScore'] = 1.0 - (df_beacon['tsMadm'] / 30.0)\n",
    "df_beacon['tsMadmScore'] = df_beacon['tsMadmScore'].apply(lambda x: 0 if x < 0 else x)\n",
    "df_beacon['tsConnCountScore'] = (df_beacon['connections_count']) / df_beacon['tsConnDiv']\n",
    "df_beacon['tsConnCountScore'] = df_beacon['tsConnCountScore'].apply(lambda x: 1.0 if x > 1.0 else x)\n",
    "df_beacon['tsScore'] = (((df_beacon['tsSkewScore'] + df_beacon['tsMadmScore'] + df_beacon['tsConnCountScore']) / 3.0) * 1000) / 1000\n",
    "\n",
    "# Data size score calculation of sent bytes\n",
    "df_beacon['dsSkewScore'] = 1.0 - abs(df_beacon['dsSkew'])\n",
    "# If data jitter is greater than 128 bytes, say 300 bytes, MadmScore might be zero\n",
    "# Depends on how the jitter is implemented. \n",
    "df_beacon['dsMadmScore'] = 1.0 - (df_beacon['dsMadm'] / 128.0)\n",
    "df_beacon['dsMadmScore'] = df_beacon['dsMadmScore'].apply(lambda x: 0 if x < 0 else x)\n",
    "# Perfect beacons don't send to much data since they are idle and just checking in, \n",
    "# division by high number makes the score insensitive. \n",
    "# Making the smallness score more sensitive as it makes more sense. \n",
    "df_beacon['dsSmallnessScore'] = 1.0 - (df_beacon['dsMid'] / 8192.0)\n",
    "df_beacon['dsSmallnessScore'] = df_beacon['dsSmallnessScore'].apply(lambda x: 0 if x < 0 else x)\n",
    "df_beacon['dsScore'] = (((df_beacon['dsSkewScore'] + df_beacon['dsMadmScore'] + df_beacon['dsSmallnessScore']) / 3.0) * 1000) / 1000\n",
    "\n",
    "# Overal Score calculation\n",
    "df_beacon['Score'] = (df_beacon['dsScore'] + df_beacon['tsScore']) / 2\n",
    "\n",
    "df_beacon.sort_values(by= 'Score', ascending=False, inplace=True, ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les connexions fréquentes ressemblants à des échanges entre des beacons et l'infrastructure C2 d'un groupe d'attaquant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beacon[columns_to_display]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualification des alertes recensées par Suricata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suricata_alert = df_suricata[(df_suricata.event_type == \"alert\") & (df_suricata['alert.category'].str.contains('Not Suspicious') == False)][['alert.severity','alert.signature_id','alert.signature','src_ip','src_port','dest_ip','dest_port','proto','app_proto','flow.start','flow_id','flow.bytes_toserver','flow.bytes_toclient']].sort_values(by=['alert.severity'], ascending=False)\n",
    "display(df_suricata_alert.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les alertes qualifiées, nous allons réaliser une extraction des IOCs potentiellement présents dans le PCAP et les rechercher dans des bases de connaissances de la menace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any IoCs in the string?\n",
    "iocs_found = ioc_extractor.extract(data=df_suricata.fillna(''), columns=['src_ip','dest_ip','dns.rrname'])\n",
    "iocs_found = iocs_found['Observable'].drop_duplicates()\n",
    "df_ti = ti.lookup_iocs(data=iocs_found, providers=[\"VirusTotal\", \"OTX\"])\n",
    "df_suspnetworkconnections = df_ti[df_ti['Result']==True]\n",
    "df_suspnetworkconnections = pd.json_normalize(data=df_suspnetworkconnections[['Ioc','Provider','Details']].to_dict(orient='records')).sort_values(by=['Details.pulse_count'], ascending=False)\n",
    "df_suspnetworkconnections[['Ioc','Provider','Details.pulse_count','Details.names','Details.references']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistiques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Déterminer les types de connexions réalisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suricata.groupby(by='event_type').size().reset_index(name='count').sort_values(by=['count'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determiner les noms de domaines recherchés\n",
    "\n",
    "Cette analyse permet de recenser les noms de domaines non communs pouvant résulter d'une attaque en cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suricata[df_suricata.event_type=='dns'][['timestamp','dns.rrname','dns.rrtype','dns.rcode','dns.grouped']].dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit ('3.11.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8acf002f28ebb43f366505f0e5b813e5533fa2e397d13c038f57c477a6eba7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
